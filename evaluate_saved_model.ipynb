{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'result/planar/noraml_train1/model_5000normal_train1/model_3000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain_e2c\u001b[39;00m \u001b[39mimport\u001b[39;00m evaluate\n\u001b[1;32m      9\u001b[0m model \u001b[39m=\u001b[39m E2C(\u001b[39m1600\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mplanar\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 10\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mresult/planar/noraml_train1/model_5000normal_train1/model_3000\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/e2c/lib/python3.8/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/e2c/lib/python3.8/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/e2c/lib/python3.8/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result/planar/noraml_train1/model_5000normal_train1/model_3000'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datasets import *\n",
    "from e2c_model import E2C\n",
    "from train_e2c import evaluate\n",
    "model = E2C(1600,2,2,'planar').cuda()\n",
    "model.load_state_dict(torch.load('result/planar/noraml_train1/model_5000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "propor = 3/4\n",
    "dataset = PlanarDataset('./data/data/planar_partial')\n",
    "train_set, test_set = dataset[:int(len(dataset) * propor)], dataset[int(len(dataset) * propor):]\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State loss: 12.65210761933395\n",
      "Next state loss: 12.661921219078062\n"
     ]
    }
   ],
   "source": [
    "state_loss, next_state_loss = evaluate(model, test_loader)\n",
    "print ('State loss: ' + str(state_loss))\n",
    "print ('Next state loss: ' + str(next_state_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8189169c18>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAACqCAYAAACTZZUqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEOklEQVR4nO3dMU4jWRRAURuZDKkXQEBCxg5YApsgYzOkELMmxAomn4QUCWqSETNliTaWq3zd5pyIL4xctD5Xn4ddvRyGYQHA/p3UFwDwUwkwQESAASICDBARYICIAANEVts8eLlces0asxqGYbnv57SvmdtX+9oJGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIqv6Ao7NMAzffuxyuZzxSmA69vU8nIABIgIMEDGC2NE2v5pt+lq/uvE7Jyfj89L6/ln//MfHx5eP3cS+3g8nYICIAANEBBggcpQz4F3mV+ZVHIrT09PR+ubmZrS+uLgYra+urkbrx8fHz49fXl5Gn9vlZ4TpOAEDRAQYICLAAJGjnAHDMVif8T49PY3WZ2dno/X63y9Wq/9+vO/u7kafe39/n+IS2ZETMEBEgAEiAgwQMQPe0frczW37mMrt7e1o/evXr9F6070hLi8vPz/edq/Z1/vhBAwQEWCAiAADRMyAJ2b+xVTOz89H6/U57Pr6//f/XSwWi+fn5y8fuy37eh5OwAARAQaICDBA5ChnwOZVHIOHh4fR+u3tbbS+vr4erV9fX0fr+/v7z4/d//cwOQEDRAQYILLc8i2Gfo9hVsMw7H1+dKj7en2Utmm96WVpdL7a107AABEBBogIMEDkKF+GBsdg01uP+fM5AQNEBBggIsAAEQEGiAgwQESAASICDBDZ2+uAt30N4y63lNznc1XK7/En/Pt+l309rZ+2r52AASICDBARYIDIbPcDnvp967+bt0z5XIc8N6u+z30+76HfD9i+nt5P3tdOwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaIzPZW5HVu2zetY71t36G/FXmdfT2tn7avnYABIgIMEBFggMjeZsDwHX/aDBi+wwwY4MAIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBkVV/Asdnyv3ia8UpgOvb1PJyAASICDBARYICIGfCOtpmNbfpaszMOhX29H07AABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBoh4K/KO1t9m6bZ9HAP7ej+cgAEiAgwQEWCAiBnwxMy/OEb29TycgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQWW35+L8Xi8Vfc1wILBaLi+h57Wvm9OW+Xg7DsM8LAeBfRhAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAkX8ArTL/DHro1LgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_idx = random.randint(0, len(test_set))\n",
    "x, u, x_next = test_set[rand_idx]\n",
    "with torch.no_grad():\n",
    "    x_next_pred = model.predict(x.unsqueeze(0).view(-1,1600).double().cuda(),\n",
    "                                torch.Tensor(u).unsqueeze(0).double().cuda())\n",
    "plt.show()\n",
    "f, axarr = plt.subplots(1,2)\n",
    "plt.setp(axarr, xticks=[], yticks=[])\n",
    "axarr[0].imshow(x_next.squeeze(), cmap='gray')\n",
    "axarr[1].imshow(x_next_pred.squeeze().view(40,40).cpu(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('e2c')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ff921ccb319ce6a40dac2c9ed8bf58e1e98289277b82324a1174465a43732f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
